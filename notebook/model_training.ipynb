{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8xaNzn0h8GB"
      },
      "source": [
        "\n",
        "# Importing libraries \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential , Model , load_model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16   # importing vgg16 model for transfered learning\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout , Input, Lambda\n",
        "from tensorflow.keras.optimizers import Adam  \n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os      \n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7k8UKt30Tyr"
      },
      "source": [
        "data_path='gdrive/My Drive/TB09'   # Give path of  your dataset folder \n",
        "os.chdir(data_path)         # Chaging path to data_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79853chO080h"
      },
      "source": [
        "# Folders name of train ,test , valid data\n",
        "\n",
        "train_path=\"train\"     \n",
        "test_path=\"test\" \n",
        "valid_path=\"val\" \n",
        "image_size = [224,224]   # targert image size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MfkYwZu30ze",
        "outputId": "0817d19b-778d-44d9-ad4e-626fff139a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "vgg = VGG16(input_shape=image_size+[3],weights='imagenet',include_top=False)  # Defining vgg16 model and parameter \n",
        "# Why to using vgg16 model ?\n",
        "#The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes\n",
        "#VGG16 was trained for weeks and was using NVIDIA Titan Black GPUâ€™s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkuSnOPf6H_I"
      },
      "source": [
        "for layers in vgg.layers:  # As vgg16 is trained on large dataset and with a lot of gpu power \n",
        "  layers.trainable = False # we dont need to train the whole model again "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zSLA9Ty6VRF"
      },
      "source": [
        "folder = os.listdir('train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWEtlTGI6fUS"
      },
      "source": [
        "x = Flatten()(vgg.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6M3tBvz9Nkk"
      },
      "source": [
        "prediction=Dense(len(folder), activation='softmax')(x) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BerD5MkT_dPl"
      },
      "source": [
        "model = Model(inputs=vgg.input ,outputs=prediction)  # Preparing model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2XY92qD_mxc",
        "outputId": "bddf94ae-6315-4404-ebb9-3d34940589a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "model.summary() # How oue model look like"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 50178     \n",
            "=================================================================\n",
            "Total params: 14,764,866\n",
            "Trainable params: 50,178\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxECXGgjAVZS"
      },
      "source": [
        "# Compiling model with Adam optimizer\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer='Adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKFGxlMaBSzK",
        "outputId": "ba967b7f-e94a-499c-8d06-56fd591dd100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# As for images we need to preprocess them before using them to train  our model\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(224,224), classes=['crack', 'not_crack'], batch_size=10)\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=valid_path, target_size=(224,224), classes=['crack', 'not_crack'], batch_size=10)\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(224,224), classes=['crack', 'not_crack'], batch_size=10, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 32000 images belonging to 2 classes.\n",
            "Found 4000 images belonging to 2 classes.\n",
            "Found 4000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zicl87TGj8v4"
      },
      "source": [
        "r =  model.fit(x=train_batches, validation_data=valid_batches, epochs=5, steps_per_epoch=180, validation_steps=10) # Training model on training dataset\n",
        "'''\n",
        "or if you have a dedicated gpu , you can use it to train your model\n",
        "with tf.device('/gpu:0'):\n",
        "  r =  model.fit(x=train_batches, validation_data=valid_batches, epochs=5, steps_per_epoch=180, validation_steps=10)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}